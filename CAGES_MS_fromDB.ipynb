{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491a20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import csv\n",
    "import pyworms\n",
    "\n",
    "# DEBUG\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\", category=UserWarning, message='.*')\n",
    "\n",
    "# Output file path\n",
    "outdir = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\MS\\\\data\\\\merged\\\\\"\n",
    "\n",
    "# THE ORIGINAL CAGES DATABASE FILE is served via WAF but cannot be queried from there\n",
    "# -> download to local HD\n",
    "#db_file = 'https://gcoos4.geos.tamu.edu/WAF/MBON/CAGES/CAGES.accdb'\n",
    "db_file = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES_ORIG\\CAGES.accdb\"\n",
    "user = 'user'\n",
    "password = 'pw'\n",
    "# open the database connection:\n",
    "cnxn = pyodbc.connect('DRIVER={{Microsoft Access Driver (*.mdb, *.accdb)}};DBQ={};Uid={};Pwd={};'.format(db_file, user, password))\n",
    "\n",
    "### GET DATA TABLES\n",
    "\n",
    "# -- TRAWLS and SPECIES\n",
    "query = 'SELECT * FROM \"Mississippi Trawls\" AS trawls LEFT JOIN \"Mississippi Species\" AS species ON \\\n",
    "trawls.[Species Code] = species.[Species Code]'\n",
    "df = pd.read_sql(query, cnxn)\n",
    "# Remove duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "# Convert Species Code back to integer\n",
    "intcols= ['Species Code', 'Sample Code', 'Measured']\n",
    "for acol in intcols:\n",
    "    df[acol] = df[acol].astype('Int64')\n",
    "\n",
    "# -- LENGTHS\n",
    "query = 'SELECT * FROM \"Mississippi Lengths\"'\n",
    "df_add = pd.read_sql(query, cnxn)\n",
    "# Convert Species Code back to integer\n",
    "intcols= ['Species Code', 'Sample Code']\n",
    "for acol in intcols:\n",
    "    df_add[acol] = df_add[acol].astype('Int64')\n",
    "df = pd.merge(df, df_add, on=['Sample Code','Species Code'],how='left')\n",
    "\n",
    "# -- CPUE\n",
    "query = 'SELECT * FROM \"Mississippi CPUE\"'\n",
    "df_add = pd.read_sql(query, cnxn)\n",
    "df_add['Species Code'] = df_add['Species Code'].astype('Int64')\n",
    "df = pd.merge(df_add, df, on=['Sample Code', 'Species Code'],how='left')\n",
    "\n",
    "# -- STATIONS\n",
    "query = 'SELECT * FROM \"Mississippi Stations\"'\n",
    "df_add = pd.read_sql(query, cnxn)\n",
    "df = pd.merge(df, df_add, on=['Station Code'],how='left')\n",
    "\n",
    "# -- HYDROLOGICAL\n",
    "query = 'SELECT * FROM \"Mississippi Hydrological\"'\n",
    "df_add = pd.read_sql(query, cnxn)\n",
    "df = pd.merge(df, df_add, on=['Sample Code'],how='left')\n",
    "\n",
    "# Close the database connection\n",
    "cnxn.close()\n",
    "\n",
    "# Generate Datetime field\n",
    "df['datestr'] = df['YYYY'].astype(str) + '-' + df['MM'].astype(str) + '-' + df['DD'].astype(str) + ' 12:00'\n",
    "df['Datetime'] = pd.to_datetime(df['datestr'], utc=True)\n",
    "\n",
    "# drop columns that are not needed for output\n",
    "df.drop(['datestr', 'YYYY', 'MM', 'DD'], axis=1, inplace=True)\n",
    "\n",
    "# sort by date\n",
    "df.sort_values(['Datetime'], axis=0, ascending=True, inplace=True, ignore_index=True)\n",
    "# Format datetime string\n",
    "df['Datetime'] = df['Datetime'].dt.strftime('%Y-%m-%dT%H:%MZ')\n",
    "\n",
    "# Get rid of spaces in column names\n",
    "for acol in df.columns.to_list():\n",
    "    df.rename({acol: acol.replace(\" \",\"\")}, axis=\"columns\", inplace=True)\n",
    "\n",
    "cols_out = [ 'Datetime','Latitude','Longitude','SampleCode','StationCode','Description','Bay','SpeciesCode','ScientificName',\n",
    "            'Phylum','Class','Order','Family','cpue','Measured','TotalNumber','TotalWeight','Length','Weight','Depth',\n",
    "            'SurfaceSalinity','BottomSalinity','AverageSalinity','SurfaceTemperature','BottomTemperature','AverageTemperature',\n",
    "            'SurfaceDO','BottomDO','AverageDO']\n",
    "\n",
    "### OUTPUT TO FILE\n",
    "# Write merged data out to a .csv file\n",
    "df[cols_out].to_csv(outdir + \"CAGES_CPUE_MS.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f26e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate ERDDAP datasets .XML -snippet using templates according to variable type\n",
    "\n",
    "## Paths \n",
    "# ouput\n",
    "xml_output = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\MS\\\\data\\\\debug\\\\\" + \"CAGES_MS_XML.txt\"\n",
    "# template files\n",
    "xml_header_temp = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\erdxml\\\\cages_erddap_xml\\\\\" + \"cages_header_template_MS.txt\"\n",
    "xml_int_temp = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\erdxml\\\\cages_erddap_xml\\\\\" + \"int_xml_template.txt\"\n",
    "xml_float_temp = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\erdxml\\\\cages_erddap_xml\\\\\" + \"float_xml_template.txt\"\n",
    "xml_string_temp = \"D:\\\\00-GCOOS\\\\00-MBON\\\\CAGES\\\\erdxml\\\\cages_erddap_xml\\\\\" + \"string_xml_template.txt\"\n",
    "\n",
    "# get types\n",
    "dt = df.dtypes.to_dict()\n",
    "int_cols = []\n",
    "float_cols = []\n",
    "string_cols = []\n",
    "\n",
    "# list types\n",
    "for akey in dt.keys():\n",
    "     if 'nt64' in str(dt[akey]):\n",
    "        int_cols.append(akey)\n",
    "     elif 'float' in str(dt[akey]):\n",
    "         float_cols.append(akey)\n",
    "     elif 'obj' in str(dt[akey]) or 'str' in str(dt[akey]):\n",
    "         string_cols.append(akey)\n",
    "\n",
    "# These belong to the header snippet (no need to generate separately):\n",
    "header_vars = ['Datetime', 'Latitude', 'Longitude']\n",
    "\n",
    "# START concatenating the tamplate snippets together\n",
    "# --\n",
    "\n",
    "# 1st, write the header to the output file\n",
    "with open(xml_output, \"w\") as output_file:\n",
    "    with open(xml_header_temp, \"r\") as file:\n",
    "        output_file.write(file.read())\n",
    "\n",
    "# Loop throgh the rest\n",
    "for acol in cols_out:\n",
    "    isPhysicalMeasurement = False\n",
    "    if acol in header_vars:\n",
    "        continue\n",
    "    elif acol in int_cols:\n",
    "        template_file = xml_int_temp\n",
    "    elif acol in float_cols:\n",
    "        template_file = xml_float_temp\n",
    "        isPhysicalMeasurement = True\n",
    "    else:\n",
    "        template_file = xml_string_temp\n",
    "    \n",
    "    # Open the xml template file for reading\n",
    "    with open(template_file, 'r') as tempfile:\n",
    "        # Read the contents of the file\n",
    "        contents = tempfile.read()\n",
    "        # Modify the contents as needed\n",
    "        mod_contents = contents.replace('_VARNAME_', acol)\n",
    "        \n",
    "        # Try to figure out the units for some\n",
    "        if isPhysicalMeasurement:\n",
    "            if 'temperature' in acol.lower():\n",
    "                mod_contents = mod_contents.replace('_UNITS_', 'degree_Celcius')\n",
    "                mod_contents = mod_contents.replace('_CATEGORY_', 'Temperature')\n",
    "                if 'air' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'air_temperature')\n",
    "                elif 'surface' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_surface_temperature')\n",
    "                elif 'bottom' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_water_temperature_at_sea_floor')\n",
    "                elif 'average' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_water_temperature')\n",
    "            elif 'turbidity' in acol.lower():\n",
    "                mod_contents = mod_contents.replace('_UNITS_', 'NTU')\n",
    "                mod_contents = mod_contents.replace('_CATEGORY_', 'Turbidity')\n",
    "                mod_contents = mod_contents.replace('_DESTNAME_', 'sea_water_turbidity')\n",
    "            elif 'salinity' in acol.lower():\n",
    "                mod_contents = mod_contents.replace('_UNITS_', 'PSU')\n",
    "                mod_contents = mod_contents.replace('_CATEGORY_', 'Salinity')\n",
    "                if 'surface' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_surface_salinity')\n",
    "                elif 'bottom' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_water_salinity_at_sea_floor')\n",
    "                elif 'average' in acol.lower():\n",
    "                    mod_contents = mod_contents.replace('_DESTNAME_', 'sea_water_salinity')\n",
    "            elif 'DO' in acol or 'dissolved' in acol.lower() or 'oxygen' in acol.lower():\n",
    "                mod_contents = mod_contents.replace('_UNITS_', 'mg l-1')\n",
    "                mod_contents = mod_contents.replace('_CATEGORY_', 'Dissolved O2')\n",
    "                mod_contents = mod_contents.replace('_DESTNAME_', acol)\n",
    "            else:\n",
    "                mod_contents = mod_contents.replace('_DESTNAME_',acol)\n",
    "\n",
    "    # Open the ouput file for appending\n",
    "    with open(xml_output, 'a') as file2:\n",
    "        # Write the modified contents back to the file\n",
    "        file2.write(mod_contents)\n",
    "\n",
    "### Add the closing tag to the output xml file:\n",
    "with open(xml_output, 'a') as output_file:\n",
    "    output_file.write(\"</dataset>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1911a520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpue',\n",
       " 'TotalWeight',\n",
       " 'Length',\n",
       " 'Weight',\n",
       " 'Latitude',\n",
       " 'Longitude',\n",
       " 'Depth',\n",
       " 'SurfaceSalinity',\n",
       " 'BottomSalinity',\n",
       " 'AverageSalinity',\n",
       " 'SurfaceTemperature',\n",
       " 'BottomTemperature',\n",
       " 'AverageTemperature',\n",
       " 'SurfaceDO',\n",
       " 'BottomDO',\n",
       " 'AverageDO']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9bc1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SampleCode', 'StationCode', 'SpeciesCode', 'Measured', 'TotalNumber']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ioos)",
   "language": "python",
   "name": "ioos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
